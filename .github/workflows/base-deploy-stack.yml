name: Deploy Infrastructure Stack

on:
  workflow_dispatch:
      inputs:
        environment:
          default: "dev"
          description: "Which environment should this run against"
          required: true
          type: choice
          options:
            - dev
            - pre-prod
            - prod
        stack:
          description: "Which stack would you like to deploy"
          required: true
          type: choice
          options:
            - ehr-repo
            - ehr-repo-db-roles
            - ehr-out-service
            - ehr-transfer-service
            - re-registration-service
            - suspension-service
            - nems-event-processor
            - deductions
            - deductions-backup
            - deductions-cross-account
            - deductions-dashboard
            - mhs
            - gp2gp-messenger
            - pds-adapter
            - mesh-forwarder
            - base-infra
            - dev-cross-account-changes
        is_deployment:
          default: false
          type: boolean
          description: "Whether to deploy"

  workflow_call:
    inputs:
      environment:
        default: dev
        description: "Environment to deploy to"
        type: string
      stack:
        description: "Stack to deploy - stack folder name"
        type: string
      alias:
        description: "Alias for the stack - i.e. deductions is referred to as deductions-infra"
        type: string
        required: false
      is_deployment:
        default: false
        type: boolean
        description: "Whether to deploy"
      ci_account:
        default: false
        description: "Are we deploying to the CI account?"
        type: boolean
      lambdas_to_build:
        default: false
        description: "Do we need to build any lambdas before deploying?"
        type: boolean

permissions:
  pull-requests: write
  id-token: write # This is required for requesting the JWT
  contents: read # This is required for actions/checkout
jobs:
  prime:
    environment: ${{ inputs.environment }}
    runs-on: ubuntu-latest
    if: inputs.stack == 'dev-cross-account-changes' && inputs.is_deployment
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Configure AWS Credentials (Read Write)
        uses: aws-actions/configure-aws-credentials@v4
        id: aws-creds
        with:
          role-to-assume: ${{ secrets.IAM_ROLE }}
          aws-region: ${{ vars.AWS_REGION }}
          mask-aws-account-id: true
          role-skip-session-tagging: true

      - name: Login to ECR
        run: |
          aws ecr get-login-password --region ${{ vars.AWS_REGION }} |
          docker login --username AWS --password-stdin "${{ steps.aws-creds.outputs.aws-account-id }}.dkr.ecr.${AWS_REGION}.amazonaws.com"

      - name: Check ECR repositories and prime if empty
        shell: bash
        run: |
          set -euo pipefail

          repos=("docker-hub/nhsdev/nia-mhs-inbound" "docker-hub/nhsdev/nia-mhs-outbound")

          for repo in "${repos[@]}"; do
            echo "Checking repository: $repo"
            exists=$(aws ecr describe-repositories --repository-names "$repo" 2>/dev/null || echo "none")

            upstream="${repo#*/}"

            if [ "$exists" = "none" ]; then
              echo "Repo $repo doesn't exist â€” will trigger pull-through import."
              prime_needed=true
            else
              image_count=$(aws ecr describe-images \
                --repository-name "$repo" \
                --query "length(imageDetails)" \
                --output text 2>/dev/null || echo 0)
              if [ "$image_count" -eq 0 ]; then
                echo "Repo $repo is empty â€” priming..."
                prime_needed=true
              else
                echo "Repo $repo already contains $image_count image(s). Skipping."
                prime_needed=false
              fi
            fi

            if [ "$prime_needed" = true ]; then
              echo "Fetching available tags from Docker Hub for $upstream"
              tags_json=$(curl -s "https://hub.docker.com/v2/repositories/${upstream}/tags?page_size=5")
              tag=$(echo "$tags_json" | jq -r '.results[].name' | grep -v null | head -n1)

              if [ -z "$tag" ]; then
                echo "âš ï¸  No tags found for $upstream on Docker Hub â€” skipping."
                continue
              fi

              echo "Priming ECR cache using tag: $tag"
              docker pull "${{ steps.aws-creds.outputs.aws-account-id }}.dkr.ecr.${{ vars.AWS_REGION }}.amazonaws.com/${repo}:${tag}" || true
            fi
          done
  deploy_stack:
    environment: ${{ !inputs.ci_account && inputs.environment || 'ci_account' }}
    env:
      GITHUB_ENV: ${{ !inputs.ci_account && inputs.environment || 'ci_account' }}
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./stacks/${{ inputs.stack }}/terraform
    steps:
    - name: Check out Repo
      uses: actions/checkout@v4
      with:
       repository: nhsconnect/orphaned-record-continuity-infrastructure
       ref: PRM-575-1
       fetch-depth: 0 

    - name: Configure AWS Credentials (Read Write)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.IAM_ROLE }}
        aws-region: ${{ vars.AWS_REGION }}
        mask-aws-account-id: true
        role-skip-session-tagging: true

    - name: Setup Terraform variables for Dev Cross Account Changes
      if: inputs.stack == 'dev-cross-account-changes'
      env:
        DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
        DOCKER_ACCESS_TOKEN: ${{ secrets.DOCKERHUB_ACCESS_TOKEN }}
      run: |
        cat > pipeline.auto.tfvars <<EOF
        dockerhub_username = "${DOCKER_USER}"
        dockerhub_access_token = "${DOCKER_ACCESS_TOKEN}"
        EOF

    - name: Setup Terraform variables
      id: vars
      if: inputs.stack != 'dev-cross-account-changes'
      run: |
        COMMON_ACCOUNT_ID=$(aws ssm get-parameter --name /repo/ci/user-input/external/aws-account-id --with-decryption | jq -r .Parameter.Value)
        cat > pipeline.auto.tfvars <<EOF
        common_account_id=$COMMON_ACCOUNT_ID
        common_account_role="CiReadOnly"
        EOF

    - name: Build lambdas with additional requirements
      if: inputs.lambdas_to_build
      run: |
        cd ../../../
        ./tasks build_lambdas

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: latest

    # - name: Terraform Format
    #   id: fmt
    #   run: |
    #     terraform fmt

    - name: Terraform Init
      id: init
      run: |
        terraform init -no-color -backend-config="key=${{ inputs.alias && inputs.alias || format('{0}-{1}', inputs.stack, inputs.environment) }}/terraform.tfstate" \
        -backend-config="bucket=${{ secrets.TF_BACKEND_BUCKET }}" \
        -backend-config="dynamodb_table=${{ secrets.TF_BACKEND_TABLE }}"
      shell: bash

    - name: Terraform Validate
      id: validate
      run: terraform validate -no-color

    - name: Terraform Plan
      id: plan
      run: |
        terraform plan -no-color -input=false -var-file="${{ vars.AWS_ENVIRONMENT }}.tfvars" -out "${{ vars.AWS_ENVIRONMENT }}.tfplan"
        terraform show -no-color ${{ vars.AWS_ENVIRONMENT }}.tfplan > ${{ vars.AWS_ENVIRONMENT }}.tfplan.txt
        echo "summary=$(grep -E 'Plan: [0-9]+ to add, [0-9]+ to change, [0-9]+ to destroy\.|No changes\. Your infrastructure matches the configuration\.' ${{ vars.AWS_ENVIRONMENT }}.tfplan.txt | sed 's/.*No changes\. Your infrastructure matches the configuration/Plan: no changes/g' | sed 's/.*Plan: //g' | sed 's/\..*//g')" >> $GITHUB_OUTPUT
      shell: bash

    - name: Add PR comment
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request' && (success() || failure())
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          // 1. Retrieve existing bot comments for the PR
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          const botComment = comments.find(comment => {
            return comment.user.type === 'Bot' && comment.body.includes('Report for ${{ inputs.stack }} environment: ${{ inputs.environment }}')
          });
            
          // 2. Prepare format of the comment
          const output = `### Report for ${{inputs.stack}} environment: ${{ inputs.environment }}
            
          #### Terraform Format and Style ğŸ–Œ\`${{ steps.fmt.outcome }}\`
            
            
          #### Terraform Initialization âš™ï¸\`${{ steps.init.outcome }}\`
            
            
          #### Terraform Validation ğŸ¤–\`${{ steps.validate.outcome }}\`
            
            
          #### Terraform Plan ğŸ“–\`${{ steps.plan.outcome }}\`
            
          Plan results: ${{ steps.plan.outputs.summary }}`;
            
          // 3. If we have a comment, update it, otherwise create a new one
          if (botComment) {
            github.rest.issues.deleteComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
            })
          }
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: output
          });

    - name: Terraform Apply
      if: inputs.is_deployment
      run: terraform apply -auto-approve -input=false ${{ vars.AWS_ENVIRONMENT }}.tfplan